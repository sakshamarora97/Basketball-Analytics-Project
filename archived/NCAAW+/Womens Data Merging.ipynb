{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import bson\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from bson.objectid import ObjectId\n",
    "from collections import defaultdict\n",
    "import timeit\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\porwa\\OneDrive - Georgia Institute of Technology\\Desktop\\GT Acad\\09 Fall 2023\\01 Practicum\\07 NCAAW\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_shots = pd.read_pickle(\"NCAAW1+ 22-23 shotsdf.pickle\")\n",
    "df_games = pd.read_pickle(\"NCAAW1+ 22-23 gamesdf.pickle\")\n",
    "df_players = pd.read_pickle(\"NCAAW1+ 22-23 playerdictionary.pickle\")\n",
    "df_players = pd.DataFrame(df_players)\n",
    "df_team = pd.read_pickle(\"NCAAW1+ 22-23 teamsdf.pickle\")\n",
    "df_games_prev_season = pd.read_pickle(\"NCAAW1+ 21-22 gamesdf.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = df_shots[['game_id', 'team_id', 'season_id', 'player_id', 'shot_id','segment_id','Distance', 'Angle', 'Zone', 'x_coordinate', 'y_coordinate', 'Period','Time_Seconds','Time','score','score_opp','Stat']].copy()\n",
    "\n",
    "# For shot/play type, we'll take multiple columns\n",
    "shot_play_type_columns = ['Jumpshot', 'Assisted', 'Red Zone', 'Floater', 'Second Chance', 'Layup', 'Paint', 'Drive', 'Blocked', 'ATO', 'Off Turnover', 'Off Steal', 'Hook Shot', 'Fastbreak', 'Pullup', 'And1', 'Turnaround', 'Dunk', 'Step Back']\n",
    "features_df[shot_play_type_columns] = df_shots[shot_play_type_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(features_df, df_games, on='game_id', how='left')\n",
    "\n",
    "# Create 'Location' feature based on 'team_id' and 'hometeam'\n",
    "def determine_location(row):\n",
    "    if pd.isna(row['hometeam']):\n",
    "        return 'Neutral'\n",
    "    elif row['team_id'] == row['hometeam']:\n",
    "        return 'Home'\n",
    "    else:\n",
    "        return 'Away'\n",
    "\n",
    "merged_df['Location'] = merged_df.apply(determine_location, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\porwa\\AppData\\Local\\Temp\\ipykernel_34756\\2950306567.py:1: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_games['date'] = pd.to_datetime(df_games['date'])\n",
      "C:\\Users\\porwa\\AppData\\Local\\Temp\\ipykernel_34756\\2950306567.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  merged_df['date'] = pd.to_datetime(merged_df['date'])\n"
     ]
    }
   ],
   "source": [
    "df_games['date'] = pd.to_datetime(df_games['date'])\n",
    "merged_df['date'] = pd.to_datetime(merged_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating DataFrame: 100%|██████████| 4/4 [02:25<00:00, 36.27s/it]\n"
     ]
    }
   ],
   "source": [
    "periods = [10, 5, 3, 1]\n",
    "\n",
    "def compute_win_loss_ratios_for_period(df_games, team_id, period):\n",
    "    \"\"\"Compute win-loss ratios for a team for the given period.\"\"\"\n",
    "    # Filter the team's games\n",
    "    team_games = df_games[(df_games['team1'] == team_id) | (df_games['team2'] == team_id)]\n",
    "    \n",
    "    # Sort by date\n",
    "    team_games = team_games.sort_values(by='date')\n",
    "    \n",
    "    # Compute win flags (1 if won, 0 otherwise)\n",
    "    team_games['won'] = (team_games['winning_team'] == team_id).astype(int)\n",
    "    \n",
    "    # Calculate rolling win sum and count, excluding the current game\n",
    "    team_games[f'wins_last_{period}'] = team_games['won'].shift(1).rolling(window=period, min_periods=1, closed='left').sum()\n",
    "    team_games[f'games_last_{period}'] = team_games['won'].shift(1).rolling(window=period, min_periods=1, closed='left').count()\n",
    "    \n",
    "    # Calculate ratio\n",
    "    team_games[f'w_l_ratio_last_{period}'] = team_games[f'wins_last_{period}'] / team_games[f'games_last_{period}']\n",
    "    \n",
    "    return team_games[['date', f'w_l_ratio_last_{period}']].set_index('date')\n",
    "\n",
    "# Calculate win-loss ratios for all teams and periods in advance\n",
    "team_ids = df_games['team1'].unique()\n",
    "ratios_cache = {}\n",
    "for team_id in team_ids:\n",
    "    for period in periods:\n",
    "        ratios_cache[(team_id, period)] = compute_win_loss_ratios_for_period(df_games, team_id, period)\n",
    "\n",
    "def get_opponent(row):\n",
    "    return row['team2'] if row['team_id'] == row['team1'] else row['team1']\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_ratio_from_cache_vectorized(dates, team_ids, period):\n",
    "    \"\"\"Vectorized function to fetch pre-calculated ratio from the cache.\"\"\"\n",
    "    results = []\n",
    "    for date, team_id in zip(dates, team_ids):\n",
    "        ratios = ratios_cache.get((team_id, period))\n",
    "        if ratios is not None:\n",
    "            results.append(ratios.loc[date, f'w_l_ratio_last_{period}'] if date in ratios.index else float('nan'))\n",
    "        else:\n",
    "            results.append(float('nan'))\n",
    "    return results\n",
    "\n",
    "for period in tqdm(periods, desc='Updating DataFrame'):\n",
    "    # Team stats\n",
    "    merged_df[f'w_l_ratio_last_{period}'] = get_ratio_from_cache_vectorized(merged_df['date'], merged_df['team_id'], period)\n",
    "    # Opposition stats\n",
    "    merged_df[f'opp_w_l_ratio_last_{period}'] = get_ratio_from_cache_vectorized(merged_df['date'], merged_df.apply(get_opponent, axis=1), period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with no player_id\n",
    "merged_df = merged_df[merged_df.player_id != False]\n",
    "\n",
    "# Remove all the corner 3s that are registered as 2s\n",
    "merged_df = merged_df[~(((merged_df.Zone == ' 4-1') & (merged_df.x_coordinate <= 3)) |\n",
    "                         ((merged_df.Zone == ' 4-3') & (merged_df.x_coordinate >= 47)))]\n",
    "\n",
    "# Remove all the above the break 3s that are registered as 2s\n",
    "merged_df = merged_df[~(((merged_df.Zone == ' 4-1') | (merged_df.Zone == ' 4-3') | (merged_df.Zone == ' 4-2')) &\n",
    "                         (merged_df.Distance >= 22.1458))]\n",
    "\n",
    "# Remove all the 2s that are registered as above the break 3s\n",
    "merged_df = merged_df[~(((merged_df.Zone == ' 6-1') | (merged_df.Zone == ' 6-3') | (merged_df.Zone == ' 6-2')) &\n",
    "                         (merged_df.Distance < 22.1458))]\n",
    "\n",
    "# Remove all the 2s that are registered as corner 3s\n",
    "merged_df = merged_df[~(((merged_df.Zone == ' 5-1') & (merged_df.x_coordinate > 3)) |\n",
    "                         ((merged_df.Zone == ' 5-2') & (merged_df.x_coordinate < 47) & (merged_df.x_coordinate > 3)))]\n",
    "\n",
    "# Reclassify the misclassified corner 3s (left instead of right corner)\n",
    "merged_df.loc[((merged_df.Zone == ' 5-2') & (merged_df.x_coordinate <= 3)), 'Zone'] = ' 5-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging Saksham's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664654, 14)\n",
      "(664654, 54)\n",
      "(664654, 67)\n"
     ]
    }
   ],
   "source": [
    "df_features_additional = pd.read_pickle(\"features_SA_NCAAW1+.pickle\")\n",
    "print(df_features_additional.shape)\n",
    "print(merged_df.shape)\n",
    "merged_df = pd.merge(merged_df, df_features_additional, on=['shot_id'], how='left')\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding player attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(664654, 73)\n",
      "(664654, 70)\n"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(merged_df, df_players, left_on='player_id', right_on='player', how='left')\n",
    "print(merged_df.shape)\n",
    "merged_df.drop(columns=['player', 'Genius_position','seasonid'], inplace=True)\n",
    "print(merged_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding previous season win-loss ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_prev_season_win_loss_ratio(df_games_prev_season):\n",
    "    team_wins = df_games_prev_season.groupby('winning_team').size()\n",
    "    team_games = df_games_prev_season.groupby(['team1']).size() + df_games_prev_season.groupby(['team2']).size()\n",
    "\n",
    "    # Win-loss ratio\n",
    "    win_loss_ratio = team_wins / team_games\n",
    "    return win_loss_ratio\n",
    "\n",
    "win_loss_ratio_prev_season = compute_prev_season_win_loss_ratio(df_games_prev_season)\n",
    "\n",
    "def get_team_wl_ratio(team_id, win_loss_ratio):\n",
    "    return win_loss_ratio.get(team_id, float('nan'))\n",
    "\n",
    "merged_df['team_wl_ratio_prev_season'] = merged_df['team_id'].apply(lambda x: get_team_wl_ratio(x, win_loss_ratio_prev_season))\n",
    "merged_df['opp_team_wl_ratio_prev_season'] = merged_df.apply(lambda row: get_team_wl_ratio(get_opponent(row), win_loss_ratio_prev_season), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into 2 pointer & 3 pointer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_two_pointers = merged_df[merged_df['Stat'].isin(['TwoMake', 'TwoMiss'])].copy()\n",
    "merged_df_three_pointers = merged_df[merged_df['Stat'].isin(['ThreeMake', 'ThreeMiss'])].copy()\n",
    "\n",
    "merged_df_two_pointers['Made'] = merged_df_two_pointers['Stat'] == 'TwoMake'\n",
    "merged_df_three_pointers['Made'] = merged_df_three_pointers['Stat'] == 'ThreeMake'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding Nikos's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(216949, 75)\n",
      "(447705, 75)\n"
     ]
    }
   ],
   "source": [
    "feature_df_3P = pd.read_pickle('Condensed_3P_features_W_df.pickle')\n",
    "feature_df_2P = pd.read_pickle('Condensed_2P_features_W_df.pickle')\n",
    "\n",
    "print(feature_df_3P.shape)\n",
    "print(feature_df_2P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(447705, 147)\n",
      "(216949, 147)\n"
     ]
    }
   ],
   "source": [
    "merged_df_with_2P = pd.merge(merged_df_two_pointers, feature_df_2P, on=['shot_id'], how='left')\n",
    "merged_df_with_3P = pd.merge(merged_df_three_pointers, feature_df_3P, on=['shot_id'], how='left')\n",
    "\n",
    "print(merged_df_with_2P.shape)\n",
    "print(merged_df_with_3P.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_with_2P.to_csv('Women_merged_df_with_2P.csv')\n",
    "merged_df_with_3P.to_csv('Women_merged_df_with_3P.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
